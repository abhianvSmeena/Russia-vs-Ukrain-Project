{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-27T09:15:42.871824Z",
     "iopub.status.busy": "2024-08-27T09:15:42.871364Z",
     "iopub.status.idle": "2024-08-27T09:15:42.923331Z",
     "shell.execute_reply": "2024-08-27T09:15:42.922378Z",
     "shell.execute_reply.started": "2024-08-27T09:15:42.871713Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:15:42.925984Z",
     "iopub.status.busy": "2024-08-27T09:15:42.925215Z",
     "iopub.status.idle": "2024-08-27T09:16:01.986199Z",
     "shell.execute_reply": "2024-08-27T09:16:01.985351Z",
     "shell.execute_reply.started": "2024-08-27T09:15:42.925940Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 1 must be a class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords \n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize \n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sentiwordnet \u001b[38;5;28;01mas\u001b[39;00m swn\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_output\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\__init__.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, prefer_gpu, require_cpu, require_gpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\pipeline\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattributeruler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdep_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01medit_tree_lemmatizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Language\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Matcher\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scorer\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\language.py:43\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_EXCEPTIONS, URL_MATCH\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlookups\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_lookups\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analyze_pipes, print_pipe_analysis, validate_attrs\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m     ConfigSchema,\n\u001b[0;32m     46\u001b[0m     ConfigSchemaInit,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     validate_init_settings,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scorer\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\pipe_analysis.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwasabi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m msg\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc, Span, Token\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dot_to_dict\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# This lets us add type hints for mypy etc. without causing circular imports\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\tokens\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_serialize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocBin\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmorphanalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MorphAnalysis\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\tokens\\_serialize.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleFrozenList, ensure_path\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vocab\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dict_proxies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpanGroups\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DOCBIN_ALL_ATTRS \u001b[38;5;28;01mas\u001b[39;00m ALL_ATTRS\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\vocab.pyx:1\u001b[0m, in \u001b[0;36minit spacy.vocab\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\tokens\\doc.pyx:49\u001b[0m, in \u001b[0;36minit spacy.tokens.doc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\schemas.py:287\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    281\u001b[0m UnderscoreValue \u001b[38;5;241m=\u001b[39m Union[\n\u001b[0;32m    282\u001b[0m     TokenPatternString, TokenPatternNumber, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m    283\u001b[0m ]\n\u001b[0;32m    284\u001b[0m IobValue \u001b[38;5;241m=\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTokenPattern\u001b[39;00m(BaseModel):\n\u001b[0;32m    288\u001b[0m     orth: Optional[StringValue] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     text: Optional[StringValue] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\main.py:197\u001b[0m, in \u001b[0;36mpydantic.main.ModelMetaclass.__new__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\fields.py:506\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField.infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\fields.py:436\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\fields.py:552\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField.prepare\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\fields.py:661\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField._type_analysis\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pydantic\\fields.py:668\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField._type_analysis\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\typing.py:852\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.__subclasscheck__\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__)\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, _GenericAlias):\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__origin__\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from pandas.io.json import json_normalize\n",
    "from wordcloud import WordCloud\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import spacy\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from IPython.display import clear_output\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode (connected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:01.993689Z",
     "iopub.status.busy": "2024-08-27T09:16:01.991206Z",
     "iopub.status.idle": "2024-08-27T09:16:02.380309Z",
     "shell.execute_reply": "2024-08-27T09:16:02.379597Z",
     "shell.execute_reply.started": "2024-08-27T09:16:01.993629Z"
    }
   },
   "outputs": [],
   "source": [
    "data2=pd.read_csv('RUfile.csv')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:02.387611Z",
     "iopub.status.busy": "2024-08-27T09:16:02.385424Z",
     "iopub.status.idle": "2024-08-27T09:16:02.405637Z",
     "shell.execute_reply": "2024-08-27T09:16:02.404569Z",
     "shell.execute_reply.started": "2024-08-27T09:16:02.387547Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Count of columns in the dataset is:  ', len(data2.columns))\n",
    "print('Count of rows in the dataset is:  ', len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:02.411536Z",
     "iopub.status.busy": "2024-08-27T09:16:02.410803Z",
     "iopub.status.idle": "2024-08-27T09:16:02.424923Z",
     "shell.execute_reply": "2024-08-27T09:16:02.424067Z",
     "shell.execute_reply.started": "2024-08-27T09:16:02.411479Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:02.428219Z",
     "iopub.status.busy": "2024-08-27T09:16:02.426775Z",
     "iopub.status.idle": "2024-08-27T09:16:02.452383Z",
     "shell.execute_reply": "2024-08-27T09:16:02.451577Z",
     "shell.execute_reply.started": "2024-08-27T09:16:02.428169Z"
    }
   },
   "outputs": [],
   "source": [
    "data2[[\"tweet\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:02.459715Z",
     "iopub.status.busy": "2024-08-27T09:16:02.457233Z",
     "iopub.status.idle": "2024-08-27T09:16:02.510399Z",
     "shell.execute_reply": "2024-08-27T09:16:02.509597Z",
     "shell.execute_reply.started": "2024-08-27T09:16:02.459650Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:02.517949Z",
     "iopub.status.busy": "2024-08-27T09:16:02.515630Z",
     "iopub.status.idle": "2024-08-27T09:16:02.531063Z",
     "shell.execute_reply": "2024-08-27T09:16:02.530012Z",
     "shell.execute_reply.started": "2024-08-27T09:16:02.517896Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:02.538477Z",
     "iopub.status.busy": "2024-08-27T09:16:02.536312Z",
     "iopub.status.idle": "2024-08-27T09:16:02.570789Z",
     "shell.execute_reply": "2024-08-27T09:16:02.569829Z",
     "shell.execute_reply.started": "2024-08-27T09:16:02.538428Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(data2.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:02.579492Z",
     "iopub.status.busy": "2024-08-27T09:16:02.577136Z",
     "iopub.status.idle": "2024-08-27T09:16:02.594413Z",
     "shell.execute_reply": "2024-08-27T09:16:02.593285Z",
     "shell.execute_reply.started": "2024-08-27T09:16:02.579438Z"
    }
   },
   "outputs": [],
   "source": [
    "data2[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:02.601823Z",
     "iopub.status.busy": "2024-08-27T09:16:02.599679Z",
     "iopub.status.idle": "2024-08-27T09:16:03.065640Z",
     "shell.execute_reply": "2024-08-27T09:16:03.064652Z",
     "shell.execute_reply.started": "2024-08-27T09:16:02.601774Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.language.value_counts().sort_values().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:03.072951Z",
     "iopub.status.busy": "2024-08-27T09:16:03.070529Z",
     "iopub.status.idle": "2024-08-27T09:16:03.083842Z",
     "shell.execute_reply": "2024-08-27T09:16:03.082891Z",
     "shell.execute_reply.started": "2024-08-27T09:16:03.072892Z"
    }
   },
   "outputs": [],
   "source": [
    "data2[\"tweet\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:03.091860Z",
     "iopub.status.busy": "2024-08-27T09:16:03.089002Z",
     "iopub.status.idle": "2024-08-27T09:16:03.103183Z",
     "shell.execute_reply": "2024-08-27T09:16:03.102050Z",
     "shell.execute_reply.started": "2024-08-27T09:16:03.091807Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to collect hashtags\n",
    "def hashtag_extract(text_list):\n",
    "    hashtags = []\n",
    "    # Loop over the words in the tweet\n",
    "    for text in text_list:\n",
    "        ht = re.findall(r\"#(\\w+)\", text)\n",
    "        hashtags.append(ht)\n",
    "\n",
    "    return hashtags\n",
    "\n",
    "def generate_hashtag_freqdist(hashtags):\n",
    "    a = nltk.FreqDist(hashtags)\n",
    "    d = pd.DataFrame({'Hashtag': list(a.keys()),\n",
    "                      'Count': list(a.values())})\n",
    "    # selecting top 15 most frequent hashtags     \n",
    "    d = d.nlargest(columns=\"Count\", n = 25)\n",
    "    plt.figure(figsize=(16,7))\n",
    "    ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\n",
    "    plt.xticks(rotation=80)\n",
    "    ax.set(ylabel = 'Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:03.112150Z",
     "iopub.status.busy": "2024-08-27T09:16:03.108802Z",
     "iopub.status.idle": "2024-08-27T09:16:03.273399Z",
     "shell.execute_reply": "2024-08-27T09:16:03.272587Z",
     "shell.execute_reply.started": "2024-08-27T09:16:03.112082Z"
    }
   },
   "outputs": [],
   "source": [
    "hashtags = hashtag_extract(data2[\"tweet\"])\n",
    "hashtags = sum(hashtags, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:03.280395Z",
     "iopub.status.busy": "2024-08-27T09:16:03.278048Z",
     "iopub.status.idle": "2024-08-27T09:16:03.742894Z",
     "shell.execute_reply": "2024-08-27T09:16:03.742101Z",
     "shell.execute_reply.started": "2024-08-27T09:16:03.280340Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_hashtag_freqdist(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:03.749248Z",
     "iopub.status.busy": "2024-08-27T09:16:03.747165Z",
     "iopub.status.idle": "2024-08-27T09:16:03.760403Z",
     "shell.execute_reply": "2024-08-27T09:16:03.759497Z",
     "shell.execute_reply.started": "2024-08-27T09:16:03.749192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "\"\"\"\n",
    "Removing ‘@names’,links (http | https),Punctuations, Numbers and Special characters. Because they don't convey any sentiment of the text\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_tweet(text):\n",
    "    text = str(text)\n",
    "    # Remove emojis\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    # Remove identifications\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove links\n",
    "    text = re.sub(r'http.?://[^/s]+[/s]?', '', text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "    \n",
    "def analyze_sentiment(tweet):\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:03.769100Z",
     "iopub.status.busy": "2024-08-27T09:16:03.765880Z",
     "iopub.status.idle": "2024-08-27T09:16:09.167676Z",
     "shell.execute_reply": "2024-08-27T09:16:09.166819Z",
     "shell.execute_reply.started": "2024-08-27T09:16:03.769038Z"
    }
   },
   "outputs": [],
   "source": [
    "data2['Sentiment'] = data2['tweet'].apply(lambda x:analyze_sentiment(x))\n",
    "data2['Source'] = 'random_user'\n",
    "data2['Length'] = data2['tweet'].apply(len)\n",
    "data2['Word_counts'] = data2['tweet'].apply(lambda x:len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.174730Z",
     "iopub.status.busy": "2024-08-27T09:16:09.172511Z",
     "iopub.status.idle": "2024-08-27T09:16:09.201690Z",
     "shell.execute_reply": "2024-08-27T09:16:09.200628Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.174678Z"
    }
   },
   "outputs": [],
   "source": [
    "data=data2[['tweet','retweets_count', 'Sentiment', 'Source', 'Length','Word_counts']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.209237Z",
     "iopub.status.busy": "2024-08-27T09:16:09.206912Z",
     "iopub.status.idle": "2024-08-27T09:16:09.215294Z",
     "shell.execute_reply": "2024-08-27T09:16:09.214442Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.209181Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.223382Z",
     "iopub.status.busy": "2024-08-27T09:16:09.220537Z",
     "iopub.status.idle": "2024-08-27T09:16:09.455827Z",
     "shell.execute_reply": "2024-08-27T09:16:09.454934Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.223323Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Clean tweet'] = data['tweet'].apply(lambda x:clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.463404Z",
     "iopub.status.busy": "2024-08-27T09:16:09.461008Z",
     "iopub.status.idle": "2024-08-27T09:16:09.479996Z",
     "shell.execute_reply": "2024-08-27T09:16:09.478906Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.463344Z"
    }
   },
   "outputs": [],
   "source": [
    "data[[\"Clean tweet\",\"Sentiment\"]].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.489649Z",
     "iopub.status.busy": "2024-08-27T09:16:09.485965Z",
     "iopub.status.idle": "2024-08-27T09:16:09.502463Z",
     "shell.execute_reply": "2024-08-27T09:16:09.501461Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.489534Z"
    }
   },
   "outputs": [],
   "source": [
    "neutral = data[data['Sentiment'] == 0]\n",
    "positive = data[data['Sentiment'] == 1]\n",
    "negative = data[data['Sentiment'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.512972Z",
     "iopub.status.busy": "2024-08-27T09:16:09.509703Z",
     "iopub.status.idle": "2024-08-27T09:16:09.654539Z",
     "shell.execute_reply": "2024-08-27T09:16:09.653446Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.512915Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ['Neutral', 'Positive', 'Negative']\n",
    "y = [len(neutral),  len(positive), len(negative)]\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "# Use the hovertext kw argument for hover text\n",
    "fig = go.Figure(data=[go.Bar(x=x, y=y,\n",
    "            hovertext=['61% of tweets', '28% of tweets', '11% of tweets'])])\n",
    "\n",
    "# Customize aspect\n",
    "#marker_color='rgb(158,202,225)'\n",
    "fig.update_traces(marker_line_color='midnightblue',\n",
    "                  marker_line_width=1.)\n",
    "fig.update_layout(title_text='Distribution of sentiment')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.662459Z",
     "iopub.status.busy": "2024-08-27T09:16:09.659965Z",
     "iopub.status.idle": "2024-08-27T09:16:09.673322Z",
     "shell.execute_reply": "2024-08-27T09:16:09.672163Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.662402Z"
    }
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.678052Z",
     "iopub.status.busy": "2024-08-27T09:16:09.677399Z",
     "iopub.status.idle": "2024-08-27T09:16:09.813486Z",
     "shell.execute_reply": "2024-08-27T09:16:09.812677Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.678010Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6, 6))\n",
    "sizes = [count for count in data['Sentiment'].value_counts()]\n",
    "labels = list(data['Sentiment'].value_counts().index)\n",
    "explode = (0.1, 0, 0)\n",
    "ax.pie(x = sizes, labels = labels, autopct = '%1.1f%%', explode = explode, textprops={'fontsize': 14})\n",
    "ax.set_title('Sentiment Polarity on invasion Tweets Data \\n (total = {})'.format(len(data)), fontsize = 16, pad = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.820636Z",
     "iopub.status.busy": "2024-08-27T09:16:09.818307Z",
     "iopub.status.idle": "2024-08-27T09:16:09.830740Z",
     "shell.execute_reply": "2024-08-27T09:16:09.829864Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.820581Z"
    }
   },
   "outputs": [],
   "source": [
    "len(neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.836981Z",
     "iopub.status.busy": "2024-08-27T09:16:09.835006Z",
     "iopub.status.idle": "2024-08-27T09:16:09.852102Z",
     "shell.execute_reply": "2024-08-27T09:16:09.851300Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.836931Z"
    }
   },
   "outputs": [],
   "source": [
    "negative.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.863024Z",
     "iopub.status.busy": "2024-08-27T09:16:09.860683Z",
     "iopub.status.idle": "2024-08-27T09:16:09.876214Z",
     "shell.execute_reply": "2024-08-27T09:16:09.875114Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.862969Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#neutral_text\n",
    "print(\"Neutral tweet example  :\",neutral['tweet'].values[15])\n",
    "# Positive tweet\n",
    "print(\"Positive Tweet example :\",positive['tweet'].values[37])\n",
    "#negative_text\n",
    "print(\"Negative Tweet example :\",negative['tweet'].values[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.880772Z",
     "iopub.status.busy": "2024-08-27T09:16:09.880198Z",
     "iopub.status.idle": "2024-08-27T09:16:09.954665Z",
     "shell.execute_reply": "2024-08-27T09:16:09.953625Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.880730Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = data.Length.values\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=x,\n",
    "                                   marker_line_width=1, \n",
    "                                   marker_line_color=\"midnightblue\", \n",
    "                                   xbins_size = 5)])\n",
    "\n",
    "fig.update_layout(title_text='Distribution of tweet lengths')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:09.956012Z",
     "iopub.status.busy": "2024-08-27T09:16:09.955772Z",
     "iopub.status.idle": "2024-08-27T09:16:10.043840Z",
     "shell.execute_reply": "2024-08-27T09:16:10.042979Z",
     "shell.execute_reply.started": "2024-08-27T09:16:09.955983Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = neutral.Length.values\n",
    "x2 = positive.Length.values\n",
    "x3 = negative.Length.values\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=x1,\n",
    "                                   marker_line_width=1, \n",
    "                                   marker_line_color=\"midnightblue\", \n",
    "                                   xbins_size = 5,\n",
    "                                   opacity = 0.5)])\n",
    "\n",
    "fig.update_layout(title_text='Distribution of neutral tweet lengths')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=x2,\n",
    "                                   marker_line_width=1, \n",
    "                                   marker_color='rgb(50,202,50)', \n",
    "                                   marker_line_color=\"midnightblue\", \n",
    "                                   xbins_size = 5,\n",
    "                                   opacity = 0.5)])\n",
    "\n",
    "fig.update_layout(title_text='Distribution of positive tweet lengths')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=x3,\n",
    "                                   marker_line_width=1, \n",
    "                                   marker_color='crimson', \n",
    "                                   marker_line_color=\"midnightblue\", \n",
    "                                   opacity = 0.5)])\n",
    "\n",
    "fig.update_layout(title_text='Distribution of negative tweet lengths')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:10.050853Z",
     "iopub.status.busy": "2024-08-27T09:16:10.048548Z",
     "iopub.status.idle": "2024-08-27T09:16:10.128956Z",
     "shell.execute_reply": "2024-08-27T09:16:10.128143Z",
     "shell.execute_reply.started": "2024-08-27T09:16:10.050802Z"
    }
   },
   "outputs": [],
   "source": [
    "y1 = neutral.Length.values\n",
    "y2 = positive.Length.values\n",
    "y3 = negative.Length.values\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Box(y=y1, \n",
    "                     name=\"Neutral\", \n",
    "                     marker_line_width=1, \n",
    "                     marker_line_color=\"midnightblue\"))\n",
    "\n",
    "fig.add_trace(go.Box(y=y2, \n",
    "                     name=\"Positive\", \n",
    "                     marker_line_width=1, \n",
    "                     marker_color = 'rgb(50,202,50)'))\n",
    "\n",
    "fig.add_trace(go.Box(y=y3, \n",
    "                     name=\"Negative\", \n",
    "                     marker_line_width=1, \n",
    "                     marker_color = 'crimson'))\n",
    "\n",
    "fig.update_layout(title_text=\"Box Plot tweet lengths\")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:10.131114Z",
     "iopub.status.busy": "2024-08-27T09:16:10.130601Z",
     "iopub.status.idle": "2024-08-27T09:16:10.164665Z",
     "shell.execute_reply": "2024-08-27T09:16:10.163666Z",
     "shell.execute_reply.started": "2024-08-27T09:16:10.131076Z"
    }
   },
   "outputs": [],
   "source": [
    "neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:10.172012Z",
     "iopub.status.busy": "2024-08-27T09:16:10.169724Z",
     "iopub.status.idle": "2024-08-27T09:16:10.260905Z",
     "shell.execute_reply": "2024-08-27T09:16:10.259990Z",
     "shell.execute_reply.started": "2024-08-27T09:16:10.171958Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_tweet = data['Clean tweet'].apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:10.267781Z",
     "iopub.status.busy": "2024-08-27T09:16:10.265529Z",
     "iopub.status.idle": "2024-08-27T09:16:19.759736Z",
     "shell.execute_reply": "2024-08-27T09:16:19.758850Z",
     "shell.execute_reply.started": "2024-08-27T09:16:10.267730Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "tokenized_tweet.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:19.766886Z",
     "iopub.status.busy": "2024-08-27T09:16:19.764429Z",
     "iopub.status.idle": "2024-08-27T09:16:23.967658Z",
     "shell.execute_reply": "2024-08-27T09:16:23.966799Z",
     "shell.execute_reply.started": "2024-08-27T09:16:19.766827Z"
    }
   },
   "outputs": [],
   "source": [
    "all_words = ' '.join([text for text in data['Clean tweet']])\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:23.974190Z",
     "iopub.status.busy": "2024-08-27T09:16:23.969354Z",
     "iopub.status.idle": "2024-08-27T09:16:26.026150Z",
     "shell.execute_reply": "2024-08-27T09:16:26.025437Z",
     "shell.execute_reply.started": "2024-08-27T09:16:23.974130Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_words =' '.join([text for text in data['Clean tweet'][data['Sentiment'] == 1]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(positive_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:26.032518Z",
     "iopub.status.busy": "2024-08-27T09:16:26.029516Z",
     "iopub.status.idle": "2024-08-27T09:16:27.853021Z",
     "shell.execute_reply": "2024-08-27T09:16:27.851987Z",
     "shell.execute_reply.started": "2024-08-27T09:16:26.032467Z"
    }
   },
   "outputs": [],
   "source": [
    "negative_words =' '.join([text for text in data['Clean tweet'][data['Sentiment'] == -1]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(negative_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:27.860534Z",
     "iopub.status.busy": "2024-08-27T09:16:27.857111Z",
     "iopub.status.idle": "2024-08-27T09:16:29.792988Z",
     "shell.execute_reply": "2024-08-27T09:16:29.792046Z",
     "shell.execute_reply.started": "2024-08-27T09:16:27.860475Z"
    }
   },
   "outputs": [],
   "source": [
    "neutral_words =' '.join([text for text in data['Clean tweet'][data['Sentiment'] == 0]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(neutral_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:29.800247Z",
     "iopub.status.busy": "2024-08-27T09:16:29.797866Z",
     "iopub.status.idle": "2024-08-27T09:16:29.808921Z",
     "shell.execute_reply": "2024-08-27T09:16:29.807894Z",
     "shell.execute_reply.started": "2024-08-27T09:16:29.800190Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to collect hashtags\n",
    "def hashtag_extract(x):\n",
    "    hashtags = []\n",
    "    # Loop over the words in the tweet\n",
    "    for i in x:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)\n",
    "\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:29.816473Z",
     "iopub.status.busy": "2024-08-27T09:16:29.812845Z",
     "iopub.status.idle": "2024-08-27T09:16:29.982354Z",
     "shell.execute_reply": "2024-08-27T09:16:29.981638Z",
     "shell.execute_reply.started": "2024-08-27T09:16:29.816412Z"
    }
   },
   "outputs": [],
   "source": [
    "HT = hashtag_extract(data['tweet'])\n",
    "HT = sum(HT,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T09:16:29.989573Z",
     "iopub.status.busy": "2024-08-27T09:16:29.987201Z",
     "iopub.status.idle": "2024-08-27T09:16:30.268845Z",
     "shell.execute_reply": "2024-08-27T09:16:30.267939Z",
     "shell.execute_reply.started": "2024-08-27T09:16:29.989503Z"
    }
   },
   "outputs": [],
   "source": [
    "a = nltk.FreqDist(HT)\n",
    "d = pd.DataFrame({'Hashtag': list(a.keys()),\n",
    "                  'Count': list(a.values())})\n",
    "# selecting top 10 most frequent hashtags     \n",
    "d = d.nlargest(columns=\"Count\", n = 10) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1955629,
     "sourceId": 5077690,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30162,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
